# ğŸ§  Hackman â€” Reinforcement Learning + HMM Hangman Agent

## ğŸ“˜ Overview
Hackman is an intelligent Hangman-playing agent built using **Hidden Markov Models (HMM)** and **Reinforcement Learning (RL)**.  
The system learns word structures from a 50,000-word corpus and trains an RL agent to guess letters efficiently, balancing exploration and exploitation.

---

## ğŸ§© Project Structure
```
Hackman/
â”‚
â”œâ”€â”€ Data/
â”‚   â”œâ”€â”€ corpus.txt               # Original dataset (50,000 words)
â”‚   â”œâ”€â”€ test.txt                 # Hidden test dataset
â”‚
â”œâ”€â”€ length_wise_disection/       # Cleaned, grouped words by length
â”‚
â”œâ”€â”€ data_clean.py                # Cleans and groups dataset
â”œâ”€â”€ hmm_oracle.py                # Builds the HMM oracle (letter probability model)
â”œâ”€â”€ hangman_env.py               # Game environment for training/testing
â”œâ”€â”€ train_agent.py               # Q-learning or DQN RL agent training
â”œâ”€â”€ play_agent.py                # Evaluation script (2000 games, scoring)
â”œâ”€â”€ q_table.pkl                  # Saved RL model (Q-table)
â”‚
â”œâ”€â”€ Analysis_Report.pdf          # Final analysis and insights (to be generated)
â”œâ”€â”€ README.md                    # This file
```

---

## âš™ï¸ Step-by-Step Workflow

### 1ï¸âƒ£ Data Cleaning
Run:
```bash
python data_clean.py
```
Creates:
- `cleaned_corpus.txt`
- `length_wise_disection/` folder grouping words by length

This ensures consistent casing, removes duplicates, and organizes words logically for the HMM.

---

### 2ï¸âƒ£ Hidden Markov Model (HMM)
Run:
```bash
python hmm_oracle.py
```
Builds a probability model that predicts letter likelihoods for partially known words.  
- Hidden states â‰ˆ letter positions  
- Emissions â‰ˆ actual letters  
- Output: `get_probs(masked_word, guessed)` returns a probability distribution over the alphabet.

---

### 3ï¸âƒ£ Reinforcement Learning Agent
Run:
```bash
python train_agent.py
```
Trains a **Q-learning** agent to play Hangman:
- **State** = (masked_word, guessed_letters)
- **Actions** = available letters (aâ€“z)
- **Rewards:**
  - +10 for correct guess
  - -1 for wrong guess
  - -5 for repeated guesses
  - +100 for win, -50 for loss
- **Exploration vs. Exploitation:** Îµ-greedy with decaying Îµ.

---

### 4ï¸âƒ£ Evaluation (Test Phase)
Run:
```bash
python play_agent.py
```
- Plays 2000 test games.
- Does **not modify** the Q-table (read-only).
- Displays per-game and final stats:
  - Success rate
  - Wrong guesses
  - Repeated guesses
  - Final Score:
    ```
    (SuccessRate * 2000) - (WrongGuesses * 5) - (RepeatedGuesses * 2)
    ```

---

## ğŸ“Š Outputs Collected for Report
You will later provide:
- **Training logs** (`reward per episode`, `Îµ decay`)
- **Evaluation summary** (wins, score)
- **Plots** of learning curve and performance  
These will go into `Analysis_Report.pdf`.

---

## ğŸ§ª Requirements
```
Python â‰¥ 3.10
numpy
pandas
matplotlib
torch (optional if using GPU/DQN)
```

Install:
```bash
pip install numpy pandas matplotlib torch
```

---

## ğŸ§  Model Summary
| Component | Type | Description |
|------------|------|-------------|
| HMM Oracle | Statistical Model | Learns letter emission probabilities from corpus |
| RL Agent | Q-learning / DQN | Learns optimal guessing strategy |
| Environment | Hangman Simulation | Provides state, reward, and word feedback |

---

## ğŸ¯ Scoring Formula
```
Final Score = (SuccessRate * 2000) - (WrongGuesses * 5) - (RepeatedGuesses * 2)
```

---

## ğŸ§© Future Work
- Move from Q-table â†’ Deep Q-Network (DQN)
- Use multi-length adaptive HMMs
- Integrate GPU-accelerated neural training
- Add reward shaping for partial progress
